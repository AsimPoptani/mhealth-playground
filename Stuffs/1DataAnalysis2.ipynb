{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = helper_functions.mhealth_get_dataset()\n",
    "subjects = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_df(df, idx):\n",
    "    return pd.DataFrame(subjects.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = []\n",
    "for i in range(0, 10):\n",
    "    sub.append(get_subject_df(subjects, i))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub[0][sub[0][23] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import mhealth_get_dataset\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Hyperparameters\n",
    "# This is how many samples per col\n",
    "data_length = 2\n",
    "\n",
    "# Prep data\n",
    "\n",
    "\n",
    "# Get the dataset\n",
    "dataset=mhealth_get_dataset()\n",
    "\n",
    "# shuffle dataset\n",
    "random.shuffle(dataset)\n",
    "\n",
    "# get 8 training users and 2 test users\n",
    "training_users,test_data = dataset[:6], dataset[6:]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lst in training_users:\n",
    "#     print(lst.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_users[0]['data'][0][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for user in training_users:\n",
    "# for user_data in training_users[0]['data']:\n",
    "#     #Removing records of no activity\n",
    "#     if user_data[23] == 0:\n",
    "#         training_users[0]['data'].remove(user_data)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in training_users:\n",
    "    user['data'] = [lst for lst in user['data'] if lst[23] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in test_data:\n",
    "    user['data'] = [lst for lst in user['data'] if lst[23] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# tr_df = pd.DataFrame(training_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_data_df = pd.DataFrame(tr_df['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_data_df[23].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From C:\\Apps\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nTrain on 71 samples, validate on 48 samples\nEpoch 1/100\n71/71 [==============================] - 0s 5ms/sample - loss: 13.7912 - acc: 0.1268 - val_loss: 30.7258 - val_acc: 0.1458\nEpoch 2/100\n71/71 [==============================] - 0s 1ms/sample - loss: 17.9408 - acc: 0.3239 - val_loss: 26.3206 - val_acc: 0.1458\nEpoch 3/100\n71/71 [==============================] - 0s 1ms/sample - loss: 11.7259 - acc: 0.4085 - val_loss: 22.1405 - val_acc: 0.2500\nEpoch 4/100\n71/71 [==============================] - 0s 845us/sample - loss: 4.8179 - acc: 0.4789 - val_loss: 27.0858 - val_acc: 0.3542\nEpoch 5/100\n71/71 [==============================] - 0s 1ms/sample - loss: 6.9782 - acc: 0.5352 - val_loss: 25.3570 - val_acc: 0.3333\nEpoch 6/100\n71/71 [==============================] - 0s 7ms/sample - loss: 4.3364 - acc: 0.5915 - val_loss: 24.6817 - val_acc: 0.3333\nEpoch 7/100\n71/71 [==============================] - 0s 1ms/sample - loss: 3.1498 - acc: 0.6197 - val_loss: 22.9727 - val_acc: 0.4375\nEpoch 8/100\n71/71 [==============================] - 0s 1ms/sample - loss: 1.6974 - acc: 0.7183 - val_loss: 22.4877 - val_acc: 0.5000\nEpoch 9/100\n71/71 [==============================] - 0s 1ms/sample - loss: 1.5561 - acc: 0.7887 - val_loss: 22.4772 - val_acc: 0.5208\nEpoch 10/100\n71/71 [==============================] - 0s 1ms/sample - loss: 1.0959 - acc: 0.8451 - val_loss: 22.2942 - val_acc: 0.5417\nEpoch 11/100\n71/71 [==============================] - 0s 3ms/sample - loss: 0.7320 - acc: 0.8592 - val_loss: 21.7810 - val_acc: 0.4792\nEpoch 12/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.3809 - acc: 0.9014 - val_loss: 20.8933 - val_acc: 0.4583\nEpoch 13/100\n71/71 [==============================] - 0s 5ms/sample - loss: 0.3704 - acc: 0.9296 - val_loss: 20.3820 - val_acc: 0.4583\nEpoch 14/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.3341 - acc: 0.9296 - val_loss: 20.0915 - val_acc: 0.4792\nEpoch 15/100\n71/71 [==============================] - 0s 2ms/sample - loss: 1.4633 - acc: 0.9014 - val_loss: 20.4160 - val_acc: 0.4375\nEpoch 16/100\n71/71 [==============================] - 0s 2ms/sample - loss: 1.2008 - acc: 0.8732 - val_loss: 19.8531 - val_acc: 0.4167\nEpoch 17/100\n71/71 [==============================] - 0s 973us/sample - loss: 0.4106 - acc: 0.9155 - val_loss: 21.0111 - val_acc: 0.4583\nEpoch 18/100\n71/71 [==============================] - 0s 564us/sample - loss: 0.3146 - acc: 0.9296 - val_loss: 19.3527 - val_acc: 0.4792\nEpoch 19/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.1327 - acc: 0.9437 - val_loss: 18.2425 - val_acc: 0.4792\nEpoch 20/100\n71/71 [==============================] - 0s 733us/sample - loss: 0.1387 - acc: 0.9296 - val_loss: 17.8405 - val_acc: 0.5208\nEpoch 21/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.1081 - acc: 0.9577 - val_loss: 18.1117 - val_acc: 0.5208\nEpoch 22/100\n71/71 [==============================] - 0s 6ms/sample - loss: 0.2180 - acc: 0.9718 - val_loss: 17.7967 - val_acc: 0.5000\nEpoch 23/100\n71/71 [==============================] - 0s 4ms/sample - loss: 0.0609 - acc: 1.0000 - val_loss: 17.4924 - val_acc: 0.5208\nEpoch 24/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0474 - acc: 1.0000 - val_loss: 17.4304 - val_acc: 0.5208\nEpoch 25/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0402 - acc: 1.0000 - val_loss: 17.4774 - val_acc: 0.5000\nEpoch 26/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0363 - acc: 1.0000 - val_loss: 17.5161 - val_acc: 0.5000\nEpoch 27/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0316 - acc: 1.0000 - val_loss: 17.5251 - val_acc: 0.5000\nEpoch 28/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0297 - acc: 1.0000 - val_loss: 17.4971 - val_acc: 0.5000\nEpoch 29/100\n71/71 [==============================] - 0s 4ms/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 17.4378 - val_acc: 0.5208\nEpoch 30/100\n71/71 [==============================] - 0s 3ms/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 17.3989 - val_acc: 0.5208\nEpoch 31/100\n71/71 [==============================] - 0s 804us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 17.3824 - val_acc: 0.5208\nEpoch 32/100\n71/71 [==============================] - 1s 7ms/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 17.3803 - val_acc: 0.5208\nEpoch 33/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 17.3904 - val_acc: 0.5208\nEpoch 34/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 17.4171 - val_acc: 0.5000\nEpoch 35/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 17.4592 - val_acc: 0.5000\nEpoch 36/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 17.4924 - val_acc: 0.4792\nEpoch 37/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 17.5087 - val_acc: 0.4792\nEpoch 38/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 17.5077 - val_acc: 0.4792\nEpoch 39/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 17.4884 - val_acc: 0.4792\nEpoch 40/100\n71/71 [==============================] - 0s 916us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 17.4710 - val_acc: 0.5208\nEpoch 41/100\n71/71 [==============================] - 0s 945us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 17.4703 - val_acc: 0.5417\nEpoch 42/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 17.4632 - val_acc: 0.5417\nEpoch 43/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 17.4523 - val_acc: 0.5417\nEpoch 44/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 17.4503 - val_acc: 0.5417\nEpoch 45/100\n71/71 [==============================] - 0s 5ms/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 17.4555 - val_acc: 0.5417\nEpoch 46/100\n71/71 [==============================] - 0s 3ms/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 17.4638 - val_acc: 0.5417\nEpoch 47/100\n71/71 [==============================] - 0s 5ms/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 17.4831 - val_acc: 0.5417\nEpoch 48/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 17.4975 - val_acc: 0.5417\nEpoch 49/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 17.5082 - val_acc: 0.5417\nEpoch 50/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 17.5219 - val_acc: 0.5208\nEpoch 51/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 17.5349 - val_acc: 0.5208\nEpoch 52/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 17.5451 - val_acc: 0.5208\nEpoch 53/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 17.5475 - val_acc: 0.5000\nEpoch 54/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 17.5404 - val_acc: 0.5000\nEpoch 55/100\n71/71 [==============================] - 0s 860us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 17.5352 - val_acc: 0.5000\nEpoch 56/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 17.5296 - val_acc: 0.5000\nEpoch 57/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 17.5336 - val_acc: 0.5417\nEpoch 58/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 17.5394 - val_acc: 0.5417\nEpoch 59/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 17.5414 - val_acc: 0.5417\nEpoch 60/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 17.5373 - val_acc: 0.5417\nEpoch 61/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 17.5343 - val_acc: 0.5208\nEpoch 62/100\n71/71 [==============================] - 0s 6ms/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 17.5386 - val_acc: 0.5208\nEpoch 63/100\n71/71 [==============================] - 0s 6ms/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 17.5460 - val_acc: 0.5208\nEpoch 64/100\n71/71 [==============================] - 0s 3ms/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 17.5535 - val_acc: 0.5208\nEpoch 65/100\n71/71 [==============================] - 0s 747us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 17.5591 - val_acc: 0.5208\nEpoch 66/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 17.5663 - val_acc: 0.5417\nEpoch 67/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 17.5747 - val_acc: 0.5417\nEpoch 68/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 17.5821 - val_acc: 0.5417\nEpoch 69/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 17.5941 - val_acc: 0.5417\nEpoch 70/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 17.6142 - val_acc: 0.5417\nEpoch 71/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 17.6266 - val_acc: 0.5417\nEpoch 72/100\n71/71 [==============================] - 0s 592us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 17.6374 - val_acc: 0.5417\nEpoch 73/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 17.6415 - val_acc: 0.5417\nEpoch 74/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 17.6627 - val_acc: 0.5208\nEpoch 75/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 17.6961 - val_acc: 0.5000\nEpoch 76/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 17.7228 - val_acc: 0.5000\nEpoch 77/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 17.7372 - val_acc: 0.5208\nEpoch 78/100\n71/71 [==============================] - 0s 804us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 17.7498 - val_acc: 0.5208\nEpoch 79/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 17.7664 - val_acc: 0.5208\nEpoch 80/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 17.7736 - val_acc: 0.5417\nEpoch 81/100\n71/71 [==============================] - 0s 3ms/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 17.7794 - val_acc: 0.5417\nEpoch 82/100\n71/71 [==============================] - 0s 3ms/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 17.7752 - val_acc: 0.5417\nEpoch 83/100\n71/71 [==============================] - 0s 6ms/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 17.7767 - val_acc: 0.5417\nEpoch 84/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 17.7760 - val_acc: 0.5417\nEpoch 85/100\n71/71 [==============================] - 0s 902us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 17.7748 - val_acc: 0.5417\nEpoch 86/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 17.7709 - val_acc: 0.5417\nEpoch 87/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 17.7708 - val_acc: 0.5417\nEpoch 88/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 17.7738 - val_acc: 0.5417\nEpoch 89/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 17.7807 - val_acc: 0.5417\nEpoch 90/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 17.7843 - val_acc: 0.5417\nEpoch 91/100\n71/71 [==============================] - 0s 2ms/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 17.7835 - val_acc: 0.5417\nEpoch 92/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 17.7843 - val_acc: 0.5417\nEpoch 93/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 17.7954 - val_acc: 0.5417\nEpoch 94/100\n71/71 [==============================] - 0s 804us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 17.8201 - val_acc: 0.5417\nEpoch 95/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 17.8448 - val_acc: 0.5417\nEpoch 96/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 17.8639 - val_acc: 0.5417\nEpoch 97/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 17.8687 - val_acc: 0.5417\nEpoch 98/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 17.8667 - val_acc: 0.5417\nEpoch 99/100\n71/71 [==============================] - 0s 1ms/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 17.8691 - val_acc: 0.5417\nEpoch 100/100\n71/71 [==============================] - 1s 9ms/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 17.8755 - val_acc: 0.5417\n0.005848126238561235\n"
    }
   ],
   "source": [
    "\n",
    "training_data_pre  = defaultdict(list) \n",
    "test_data_pre =defaultdict(list)\n",
    "\n",
    "counter=0\n",
    "previous_label=None\n",
    "to_put=[]\n",
    "for user in training_users:\n",
    "    for user_data in user['data']:\n",
    "        if not previous_label==user_data[23]:\n",
    "            counter=1\n",
    "            to_put=[]\n",
    "            previous_label=user_data[23]\n",
    "            user_data.pop()\n",
    "            to_put+=user_data\n",
    "        elif previous_label==user_data[23]:\n",
    "            counter+=1\n",
    "            user_data.pop()\n",
    "            to_put+=user_data\n",
    "        if counter == data_length:\n",
    "            training_data_pre[previous_label].append(to_put)\n",
    "            to_put=[]\n",
    "\n",
    "counter=0\n",
    "previous_label=None\n",
    "to_put=[]\n",
    "for user in test_data:\n",
    "    for user_data in user['data']:\n",
    "        if not previous_label==user_data[23]:\n",
    "            counter=1\n",
    "            to_put=[]\n",
    "            previous_label=user_data[23]\n",
    "            user_data.pop()\n",
    "            to_put+=user_data\n",
    "        elif previous_label==user_data[23]:\n",
    "            counter+=1\n",
    "            user_data.pop()\n",
    "            to_put+=user_data\n",
    "        if counter == data_length:\n",
    "            test_data_pre[previous_label].append(to_put)\n",
    "            to_put=[]\n",
    "\n",
    "training_data,training_labels=[],[]\n",
    "test_data,test_labels=[],[]\n",
    "\n",
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[nb_classes])\n",
    "\n",
    "for training_label,training in training_data_pre.items():\n",
    "    for train in training:\n",
    "        training_labels.append(int(training_label))\n",
    "        training_data.append(train)\n",
    "\n",
    "training_data=np.array(training_data)\n",
    "\n",
    "\n",
    "for training_label,training in test_data_pre.items():\n",
    "    for train in training:\n",
    "        test_labels.append(int(training_label))\n",
    "        test_data.append(train)\n",
    "\n",
    "test_data=np.array(test_data)\n",
    "\n",
    "training_labels_len=len(training_labels)\n",
    "labels=training_labels+test_labels\n",
    "labels=get_one_hot(np.array(labels),13)\n",
    "training_labels=labels[:training_labels_len]\n",
    "test_labels=labels[training_labels_len:]\n",
    "\n",
    "# Okay lets create our model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(data_length*23), # Our input layer\n",
    "    tf.keras.layers.Dense(500,activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(500),\n",
    "    tf.keras.layers.Dense(13,activation=tf.keras.activations.softmax) # Our output layer we have 13 classifcations\n",
    "\n",
    "])\n",
    "# Compile our model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_data,training_labels,validation_data=(test_data,test_labels),epochs=100)\n",
    "# -9.2305,3.9479,-4.0236,0.10884,-0.058608,3.4836,-7.467,-8.0885,0.24675,-0.78799,-0.21807,0.19791,18.714,5.4366,2.2399,-5.5648,7.5238,0.47255,-0.25051,1.0172,9.3079,-2.787,-15.309,9\n",
    "# -8.6677,3.5852,-4.5615,-0.054422,0.22606,-0.75304,-7.1983,-5.9716,0.24675,-0.78799,-0.21807,0.25394,7.7039,9.586,-0.92224,-5.7833,9.6692,0.47255,-0.25051,1.0172,4.6822,1.4321,-15.444,9\n",
    "test_array = np.array([[-9.2305,3.9479,-4.0236,0.10884,-0.058608,3.4836,-7.467,-8.0885,0.24675,-0.78799,-0.21807,0.19791,18.714,5.4366,2.2399,-5.5648,7.5238,0.47255,-0.25051,1.0172,9.3079,-2.787,-15.309,-8.6677,3.5852,-4.5615,-0.054422,0.22606,-0.75304,-7.1983,-5.9716,0.24675,-0.78799,-0.21807,0.25394,7.7039,9.586,-0.92224,-5.7833,9.6692,0.47255,-0.25051,1.0172,4.6822,1.4321,-15.444]])\n",
    "\n",
    "print(model.predict([test_array])[0][8]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}